model:
  target: modules.model.TransformerP2T
  params:
    base_learning_rate: 0.001 
    monitor: valid/loss 
    d_model: 512 
    nhead: 4 
    dim_feedforward: 1024
    activation: relu
    n_layers: 2
    emb_dim: 512
    max_len: 512
    text_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/train.text
    gloss_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/train.gloss
    text_vocab_cache: /home/ejhwang/plsl/cache/text_vocab.json
    gloss_vocab_cache: /home/ejhwang/plsl/cache/gloss_vocab.json
    vocab_freq: 1
    num_joints: 50
    num_feats: 3
    noise_config:
      target: modules.noise_scheduler.LinearNoiseScheduler
      params:
        initial_noise_std: 0.5
        final_noise_std: 0.1
        total_steps: 100000 # TODO
data:
  target: modules.datamodule.DataModuleFromConfig
  params:
    batch_size: 32
    num_workers: 16
    train:
      target: modules.data.Phoenix2014T
      params:
        text_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/train.text
        gloss_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/train.gloss
        keypoint_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/train.skels
    validation:
      target: modules.data.Phoenix2014T
      params:
        text_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/dev.text
        gloss_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/dev.gloss
        keypoint_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/dev.skels 
    test:
      target: modules.data.Phoenix2014T
      params:
        text_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/test.text
        gloss_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/test.gloss
        keypoint_file_path: /data/sl_datasets/phoenix14t/data/ProgressiveTransformersSLP/test.skels 
lightning:
  callback:
    keypoint_logger_callback:
      target: modules.callbacks.KeypointsLogger
      params:
        max_keypoints: 1
        save_and_sample_every: 1
    cuda_callback:
      target: modules.callbacks.CUDACallback
    learning_rate_logger:
      target: main.LearningRateMonitor
      params:
        logging_interval: step 
  trainer:
    accumulate_grad_batch: 2
    accelerator: gpu
    devices: auto
    max_epochs: 2
    overfit_batches: 0.1